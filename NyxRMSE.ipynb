{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da1a364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model fitting:  25%|██▌       | 1/4 [00:00<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ours complete fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model fitting:  50%|█████     | 2/4 [01:15<01:29, 44.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copula complete fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model fitting:  75%|███████▌  | 3/4 [02:10<00:49, 49.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-hist complete fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model fitting: 100%|██████████| 4/4 [03:19<00:00, 49.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "總進度: 100%|██████████| 216000/216000 [31:49<00:00, 113.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload ,import_module\n",
    "import module.utilize as utilize\n",
    "import module.multiVariant as multiVariant\n",
    "import module.singleVariant as singleVariant\n",
    "import module.multiHistogramBase as multiHistogramBase\n",
    "import numpy as np\n",
    "from numba import njit,jit, float32\n",
    "import module.singleVariantCopulaBase as CopulaBase\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import cupy as cp\n",
    "import module.multiHistogramSparse as multiHistogramSparse\n",
    "reload(utilize)\n",
    "reload(multiVariant)\n",
    "reload(singleVariant)\n",
    "reload(multiHistogramBase)\n",
    "reload(CopulaBase)\n",
    "reload(multiHistogramSparse)\n",
    "\n",
    "\n",
    "startTime=time.time()\n",
    "\n",
    "#attribute_names=np.array([\"phi_grav\",\"particle_mass_density\",\"zmom\",\"ymom\"])\n",
    "attribute_names=np.array([\"phi_grav\",\"particle_mass_density\",\"zmom\",\"ymom\"])\n",
    "incremental_number=300\n",
    "all_ensamble_data=np.empty([0,incremental_number,64,64,64])\n",
    "\n",
    "for name in attribute_names:\n",
    "    data=utilize.readFiles(name,incremental_number)\n",
    "    data=data.reshape(1,incremental_number,64,64,64)\n",
    "    all_ensamble_data=np.append(all_ensamble_data,data,axis=0)\n",
    "\n",
    "#print(all_ensamble_data.shape)\n",
    "#print(all_ensamble_data[0].shape)\n",
    "covBlockSize=5\n",
    "dataBlockSize=5\n",
    "binsNumber=128\n",
    "sizeZ=60\n",
    "sizeY=60\n",
    "sizeX=60\n",
    "minMaxBlockSize=2\n",
    "isMinMax=False\n",
    "\n",
    "print(\"start fit model\")\n",
    "with tqdm(total=4, desc=\"Model fitting\") as pbar:\n",
    "    #oursModel=multiVariant.multiDistCopula3D(all_ensamble_data,dataBlockSize,covBlockSize,binsNumber,[sizeZ,sizeY,sizeX],minMaxBlockSize,isMinMax)\n",
    "    oursModel=multiVariant.multiDistCopula3D.load(f\"Nyx_{attribute_names.shape[0]}varaibles_{incremental_number}members_128Bins_dBlock5_cBlock2_new\")\n",
    "    #conditions=np.array([[0,1e5],[3e10,5e10]])\n",
    "    #oursModel.fit()\n",
    "    print(\"ours complete fit\")\n",
    "    pbar.update(1)\n",
    "    copulaBlockSize=2\n",
    "    copulaBaseModel=CopulaBase.multiVariantCopulaBase(all_ensamble_data,copulaBlockSize)\n",
    "    copulaBaseModel.fit()\n",
    "    print(\"copula complete fit\")\n",
    "    pbar.update(1)\n",
    "    multiHistBlockSize=2\n",
    "    multiHistModel=multiHistogramSparse.multiHistogramSpaseModel(all_ensamble_data,blockSize=multiHistBlockSize,binsNumber=binsNumber)\n",
    "    multiHistModel.fit()\n",
    "    print(\"multi-hist complete fit\")\n",
    "    pbar.update(1)\n",
    "    gtModel=multiHistogramSparse.multiHistogramSpaseModel(all_ensamble_data,blockSize=1,binsNumber=binsNumber)\n",
    "    gtModel.fit()\n",
    "\n",
    "    multiBinEdges=gtModel.vBinEdges\n",
    "\n",
    "    print(\"complete fit\")\n",
    "    pbar.update(1)\n",
    "\n",
    "oursError=[]\n",
    "copulaError=[]\n",
    "mtError=[]\n",
    "\n",
    "\n",
    "#multiBinEdges=cp.asarray(multiBinEdges,dtype=cp.float32)\n",
    "\n",
    "\n",
    "with tqdm(total=sizeZ*sizeY*sizeX, desc=\"總進度\") as pbar:\n",
    "    for idx in range(sizeZ * sizeY * sizeX):\n",
    "        \n",
    "        z = idx // (sizeY * sizeX)\n",
    "        y = (idx // sizeX) % sizeY\n",
    "        x = idx % sizeX        \n",
    "        ### GroundTruth ###\n",
    "\n",
    "        gtMultiHistModel=gtModel.getHistByPos(z,y,x)\n",
    "\n",
    "        ### ours method ###\n",
    "\n",
    "        oursSamples=oursModel.sampleByPos(z,y,x)\n",
    "        oursHistModel=multiHistogramSparse.SparseMultiHistogramBlock(bin_edges=multiBinEdges)\n",
    "        oursHistModel.add_samples(oursSamples)\n",
    "        oursHistModel.normalize()\n",
    "\n",
    "        rmse=multiHistogramSparse.rmseForSparseHistogram(gtMultiHistModel,oursHistModel)\n",
    "        oursError.append(rmse)\n",
    "\n",
    "       \n",
    "        ### copula Base ###\n",
    "    \n",
    "        copulaSamples=copulaBaseModel.sampleByPos(z,y,x)\n",
    "        copulaHistModel=multiHistogramSparse.SparseMultiHistogramBlock(bin_edges=multiBinEdges)\n",
    "        copulaHistModel.add_samples(copulaSamples)\n",
    "        copulaHistModel.normalize()\n",
    "      \n",
    "        rmse=multiHistogramSparse.rmseForSparseHistogram(gtMultiHistModel,copulaHistModel)\n",
    "        copulaError.append(rmse)\n",
    "        \n",
    "\n",
    "        ### multiHist ###\n",
    "\n",
    "        ProcessTime=time.time()\n",
    "        ProcessHistTime=time.time()\n",
    "        mtMultiHistModel=multiHistModel.getHistByPos(z,y,x)\n",
    "        processHistTimeEnd=time.time()\n",
    "        #print(f\"multi hist hist 執行時間:{processHistTimeEnd-ProcessHistTime}\")\n",
    "        processRmseTime=time.time()\n",
    "        rmse=multiHistogramSparse.rmseForSparseHistogram(gtMultiHistModel,mtMultiHistModel)\n",
    "        processRmseTimeEnd=time.time()\n",
    "        #print(f\"multi hist RMSE 執行時間:{processRmseTimeEnd-processRmseTime}\")\n",
    "        mtError.append(rmse)\n",
    "\n",
    "        ProcessTimeEnd=time.time()\n",
    "        #print(f\"multi hist 執行時間:{ProcessTimeEnd-ProcessTime}\")\n",
    "        \n",
    "        pbar.update(1)\n",
    "    \n",
    "\n",
    "oursError=np.array(oursError)\n",
    "copulaError=np.array(copulaError)\n",
    "mtError=np.array(mtError)\n",
    "\n",
    "oursError=oursError.mean()\n",
    "copulaError=copulaError.mean()\n",
    "mtError=mtError.mean()\n",
    "\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "Outputfilename = f\"output_{timestamp}.txt\"\n",
    "end_Time=time.time()\n",
    "\n",
    "with open(Outputfilename , \"w\", encoding=\"utf-8\") as f:\n",
    "    print(f\"ours error:{oursError.mean()}\",file=f)\n",
    "    print(f\"copula error:{copulaError.mean()}\",file=f)\n",
    "    print(f\"mt error: {mtError.mean()}\",file=f)\n",
    "    print(f\"執行時間:{end_Time-startTime}\",file=f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
